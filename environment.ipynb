{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extreme-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "import heapq\n",
    "\n",
    "np.random.seed(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "twenty-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subtask:\n",
    "    def __init__(self, comp_demand, link_demand, order, proc_node):\n",
    "        self.comp_demand = comp_demand\n",
    "        self.link_demand = link_demand\n",
    "        self.ori_link_demand = link_demand\n",
    "        self.order = order\n",
    "        self.proc_node = proc_node\n",
    "        \n",
    "        \n",
    "    def recover_link_demand(self):\n",
    "        self.link_demand = ori_link_demand\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"({self.comp_demand}, {self.link_demand})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "random-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "class job:\n",
    "    def __init__(self, source, destination, model, birth):\n",
    "        self.source = source\n",
    "        self.destination = destination\n",
    "        self.model = model\n",
    "        self.subtasks = []\n",
    "        self.offloading = []\n",
    "        self.routing = []\n",
    "        self.birth = birth\n",
    "        self.index = -1\n",
    "    \n",
    "    def add_subtasks(self):\n",
    "        for order in range(self.model+2):\n",
    "            self.subtasks.append(subtask(10, 3, order, self.offloading[order]))\n",
    "            \n",
    "    def assign_index(self, index):\n",
    "        self.index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "floating-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class job_waiting_queue:\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque()\n",
    "            \n",
    "    def push(self, job):\n",
    "        self.buffer.append(job)\n",
    "        \n",
    "    def pop(self):\n",
    "        return self.buffer.popleft()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "double-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "class backlog:\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque()\n",
    "    \n",
    "    def push(self, job):\n",
    "        self.buffer.append(job)\n",
    "    \n",
    "    def pop(self):\n",
    "        return self.buffer.popleft()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "underlying-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class system_manager():\n",
    "    def __init__(self, network, job_waiting_queue, backlog):\n",
    "        self.network = network\n",
    "        self.job_waiting_queue = job_waiting_queue\n",
    "        self.backlog = backlog\n",
    "        self.activated_job = [None]*10 # 현재 system 안에서 돌아가고 있는 jobs.\n",
    "        self.activated_job_num = 0\n",
    "        self.src_dst_pair = []\n",
    "        for src in range(5):\n",
    "            for dst in range(5):\n",
    "                if src == dst:\n",
    "                    continue\n",
    "                self.src_dst_pair.append([src, dst])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def create_job(self, time):\n",
    "        job_num = np.random.poisson(lam=1, size=len(self.src_dst_pair))\n",
    "        for index in range(len(self.src_dst_pair)):\n",
    "            src, dst = self.src_dst_pair[index]\n",
    "            for _ in range(job_num[index]):\n",
    "                model = random.randint(1, 3)\n",
    "                new_job = job(src, dst, model, time)\n",
    "                if len(self.job_waiting_queue) < 30:\n",
    "                    self.job_waiting_queue.push(new_job)\n",
    "                else:\n",
    "                    self.backlog.push(new_job)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def move_job(self):\n",
    "        while len(self.job_waiting_queue) < 30:\n",
    "            if len(self.backlog) == 0:\n",
    "                break\n",
    "            else:\n",
    "                job = self.backlog.pop()\n",
    "                self.job_waiting_queue.push(job)\n",
    "                \n",
    "                \n",
    "                \n",
    "    def find_index(self):\n",
    "        for index, room in enumerate(self.activated_job):\n",
    "            if room == None:\n",
    "                return index\n",
    "                \n",
    "                \n",
    "                \n",
    "    def schedule_job(self):\n",
    "        while self.activated_job_num < 10 and len(self.job_waiting_queue) != 0:\n",
    "            # 지금 job의 index 계산\n",
    "            index = self.find_index()\n",
    "            \n",
    "            job = self.job_waiting_queue.pop()\n",
    "            job.assign_index(index)\n",
    "            self.activated_job[index] = job\n",
    "            \n",
    "            src, dst = job.source, job.destination\n",
    "            \n",
    "            # offloading scheduling\n",
    "            for order in range(job.model+2):\n",
    "                node = random.randint(0, 4)\n",
    "                job.offloading.append(node)\n",
    "            job.add_subtasks()\n",
    "            \n",
    "            print(\"offloading)\")\n",
    "            for k in job.offloading:\n",
    "                print(k, end=' ')\n",
    "            print()\n",
    "            \n",
    "            # transfer output data logic\n",
    "            if dst != job.offloading[-1]:\n",
    "                job.offloading.append(dst)\n",
    "            \n",
    "            # transfer input data logic\n",
    "            if src == job.offloading[0]:\n",
    "                self.network.nodes[src].push(job)\n",
    "            else:\n",
    "                job.subtasks.insert(0, subtask(0, 3, -1, -1))\n",
    "                path = self.network.routing(src, job.offloading[0])\n",
    "                job.routing = path\n",
    "                self.network.links[f'{path[0]}{path[1]}'].push(job)\n",
    "                self.network.links[f'{path[0]}{path[1]}'].waiting += 3\n",
    "                del job.routing[0]\n",
    "                \n",
    "            self.activated_job_num += 1\n",
    "            break\n",
    "                \n",
    "                \n",
    "    \n",
    "    def get_state(self):\n",
    "        node_waiting_vector = [[0]*(5*10) for _ in range(5)]\n",
    "        node_processing_vector = [[0]*(5*10) for _ in range(5)]\n",
    "        \n",
    "        # get node waiting vector\n",
    "        for job_idx, job in enumerate(self.activated_job):\n",
    "            if job == None:\n",
    "                continue\n",
    "            for subtask in job.subtasks:\n",
    "                order, proc_node, rem_comp_demand = subtask.order, subtask.proc_node, subtask.comp_demand\n",
    "                if order >= 0:\n",
    "                    node_waiting_vector[proc_node][5*job_idx+order] = rem_comp_demand\n",
    "                    \n",
    "        # get node processing vector\n",
    "        for node_idx, node in enumerate(self.network.nodes):\n",
    "            job_idx, order = node.cur_proc_job, node.cur_proc_subtask\n",
    "            if job_idx != -1 and order != -1:\n",
    "                node_processing_vector[node_idx][5*job_idx+order] = 1\n",
    "        \n",
    "        print('node waiting vector)')\n",
    "        for node in range(5):\n",
    "            cnt = 0\n",
    "            for s in range(50):\n",
    "                print(node_waiting_vector[node][s], end='')\n",
    "                cnt += 1\n",
    "                if cnt == 5:\n",
    "                    print(' | ', end=' ')\n",
    "                    cnt = 0\n",
    "            print()\n",
    "        print()\n",
    "        \n",
    "        print('node processing vector)')\n",
    "        for node in range(5):\n",
    "            cnt = 0\n",
    "            for s in range(50):\n",
    "                print(node_processing_vector[node][s], end='')\n",
    "                cnt += 1\n",
    "                if cnt == 5:\n",
    "                    print(' | ', end=' ')\n",
    "                    cnt = 0\n",
    "            print()\n",
    "        print()\n",
    "        return node_waiting_vector, node_processing_vector\n",
    "            \n",
    "        \n",
    "        \n",
    "    def step(self, time):\n",
    "        #print(f'act : {self.activated_job_num}, wait : {len(self.job_waiting_queue)}, blog : {len(self.backlog)}')\n",
    "        completed_job_index = self.network.step(time)\n",
    "        for index in completed_job_index:\n",
    "            self.activated_job[index] = None\n",
    "            self.activated_job_num -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dynamic-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.waiting_queue = collections.deque()\n",
    "        self.cur_proc_job = -1\n",
    "        self.cur_proc_subtask = -1\n",
    "    \n",
    "    def push(self, job):\n",
    "        self.waiting_queue.append(job)\n",
    "        \n",
    "    def pop(self):\n",
    "        return self.waiting_queue.popleft()\n",
    "\n",
    "    def get_info(self, index):\n",
    "        if len(self.waiting_queue) == 0:\n",
    "            return\n",
    "        print(index)\n",
    "        for job in self.waiting_queue:\n",
    "            print(job.subtasks[0], end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "undefined-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class link:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.waiting_queue = collections.deque()\n",
    "        self.cur_remain = 0\n",
    "        self.waiting = 0\n",
    "        \n",
    "    def push(self, job):\n",
    "        self.waiting_queue.append(job)\n",
    "        \n",
    "    def pop(self):\n",
    "        return self.waiting_queue.popleft()\n",
    "    \n",
    "    def get_waiting(self):\n",
    "        return self.waiting\n",
    "    \n",
    "    def get_info(self, index):\n",
    "        if len(self.waiting_queue) == 0:\n",
    "            return\n",
    "        else:\n",
    "            print(index)\n",
    "            for job in self.waiting_queue:\n",
    "                print(job.subtasks[0], end=' ')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acquired-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "        self.links = {}\n",
    "        self.adjacent = [[1, 2], [0, 2, 3], [0, 1, 3, 4], [1, 2, 4], [2, 3]]\n",
    "        for n in range(5):\n",
    "            self.nodes.append(node(10))\n",
    "        for src in range(5):\n",
    "            for dst in self.adjacent[src]:\n",
    "                self.links[f'{src}{dst}'] = link(10)\n",
    "                \n",
    "                \n",
    "    def step(self, time):\n",
    "        #print(\"--------------------------------------------------------------\")\n",
    "        completed_job_index = []\n",
    "        job_index1 = self.step_link(time)\n",
    "        job_index2 = self.step_node(time)\n",
    "        completed_job_index.extend(job_index1)\n",
    "        completed_job_index.extend(job_index2)\n",
    "        return completed_job_index\n",
    "        '''\n",
    "        print(\"node)\")\n",
    "        for index, node in enumerate(self.nodes):\n",
    "            node.get_info(index)\n",
    "        print(\"\\nlink)\")\n",
    "        for key, link in self.links.items():\n",
    "            link.get_info(key)\n",
    "        print('\\n')\n",
    "        '''\n",
    "            \n",
    "\n",
    "    \n",
    "    def step_node(self, time):\n",
    "        completed_job_index = []\n",
    "        for node_index, node in enumerate(self.nodes):\n",
    "            if len(node.waiting_queue) == 0:\n",
    "                continue\n",
    "            job = node.waiting_queue[0]\n",
    "            rem_tasks = job.subtasks\n",
    "            rem_tasks[0].comp_demand = max(0, rem_tasks[0].comp_demand-(node.capacity*0.1))\n",
    "            \n",
    "            # record current processing task\n",
    "            node.cur_proc_job = job.index\n",
    "            node.cur_proc_subtask = rem_tasks[0].order\n",
    "            \n",
    "            if rem_tasks[0].comp_demand == 0:\n",
    "                node.cur_proc_job = -1\n",
    "                node.cur_proc_task = -1\n",
    "                if len(job.offloading) == 1:\n",
    "                    #print(f'completion time {(time-job.birth)/10}')\n",
    "                    completed_job_index.append(job.index)\n",
    "                    node.pop()\n",
    "                else:\n",
    "                    start, end = job.offloading[0], job.offloading[1]\n",
    "                    if start != end:\n",
    "                        path = self.routing(start, end)\n",
    "                        job.routing = path\n",
    "                        self.links[f'{path[0]}{path[1]}'].push(job)\n",
    "                        self.links[f'{path[0]}{path[1]}'].waiting += rem_tasks[0].link_demand\n",
    "                        #print(f\"node to flow : {path[0]} {path[1]}\")\n",
    "                        del job.routing[0]\n",
    "                        node.pop()\n",
    "                    else:\n",
    "                        del rem_tasks[0]\n",
    "                    del job.offloading[0]\n",
    "                \n",
    "                    \n",
    "        return completed_job_index\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    def step_link(self, time):\n",
    "        completed_job_index = []\n",
    "        for key, link in self.links.items():\n",
    "            if len(link.waiting_queue) == 0:\n",
    "                continue\n",
    "            job = link.waiting_queue[0]\n",
    "            rem_tasks = job.subtasks\n",
    "            rem_tasks[0].link_demand = max(0, rem_tasks[0].link_demand-(link.capacity*0.1))\n",
    "            link.waiting = max(0, link.waiting-(link.capacity*0.1))\n",
    "            \n",
    "            if rem_tasks[0].link_demand == 0:\n",
    "                # 해당 layer의 destination node에 도달했다면\n",
    "                if len(job.routing) == 1:\n",
    "                    del rem_tasks[0]\n",
    "                    if len(job.offloading) != 1:\n",
    "                        node = job.routing[0]\n",
    "                        self.nodes[node].push(job)\n",
    "                    # job completion\n",
    "                    else:\n",
    "                        #print(f'completion time {(time-job.birth)/10}')\n",
    "                        completed_job_index.append(job.index)\n",
    "                else:\n",
    "                    rem_tasks[0].link_demand = rem_tasks[0].ori_link_demand # recover data size\n",
    "                    start, end = job.routing[0], job.routing[1]\n",
    "                    #print(f\"link to flow : {start} {end}\")\n",
    "                    self.links[f'{start}{end}'].push(job)\n",
    "                    self.links[f'{start}{end}'].waiting += rem_tasks[0].link_demand\n",
    "                    del job.routing[0]\n",
    "                    \n",
    "                link.pop()\n",
    "        \n",
    "        return completed_job_index\n",
    "                \n",
    "         \n",
    "        \n",
    "    def routing(self, start, end):\n",
    "        graph = [[] for _ in range(5)]\n",
    "        pre = [0]*5\n",
    "        distance = [10000]*5\n",
    "        for src in range(5):\n",
    "            for dst in self.adjacent[src]:\n",
    "                cost = self.links[f'{src}{dst}'].get_waiting()/self.links[f'{src}{dst}'].capacity\n",
    "                graph[src].append((dst, cost))\n",
    "                \n",
    "        q = [(0, start)]\n",
    "        distance[start] = 0\n",
    "        while q:\n",
    "            dist, idx = heapq.heappop(q)\n",
    "            if dist != distance[idx]:\n",
    "                continue\n",
    "            for nidx, cost in graph[idx]:\n",
    "                if distance[nidx] > dist+cost:\n",
    "                    distance[nidx] = dist+cost\n",
    "                    pre[nidx] = idx\n",
    "                    heapq.heappush(q, (distance[nidx], nidx))\n",
    "                    \n",
    "        path = []\n",
    "        cur_node = end\n",
    "        while cur_node != start:\n",
    "            path.append(cur_node)\n",
    "            cur_node = pre[cur_node]\n",
    "        path.append(start)\n",
    "        path.reverse()\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-profit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-capital",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-newspaper",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
