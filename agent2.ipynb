{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "massive-norman",
   "metadata": {},
   "source": [
    "## DRL 코드입니다.\n",
    "* 저는 이 코드와 제가 만든 환경을 가지고 학습을 했지만, 실제로는 OMNeT++와 이 이 코드를 연동시켜주셔야 합니다.\n",
    "* 그러므로 제가 만든 환경 코드는 이해하실 필요가 없습니다. 이 코드의 DNN 구조와, 환경과 상호작용하는 인터페이스 부분만 참고해주시면 될 듯 합니다.\n",
    "* main 부분은 아키텍처 설명한 ppt를 보시고 새로 짜시는게 더 빠를 수 있습니다.\n",
    "* DQN based가 아닌, Policy gradient based인 actor-critic을 쓰고자 합니다(많은 스케줄링 관련 논문에서 actor-critic 사용. 또한 DQN은 규모가 좀 커지면 학습 힘들다고 알고 있음).\n",
    "* actor-critic 알고리즘은 다양합니다. 저희는 A3C 혹은 PPO를 쓸 것 같습니다. 각 알고리즘에 대해선 논문을 읽어보시거나 검색하셔서 이해해주시면 될 것 같습니다.\n",
    "* actor network로 GNN(Graph Neural Network)를 사용합니다. Pytorch geometric library에서 다양한 GNN 모듈을 제공합니다. 저희는 Dynamic edge-conditioned GNN을 씁니다.\n",
    "* Dynamic edge-conditioned GNN : https://arxiv.org/abs/1704.02901\n",
    "* 코드 기반 : https://github.com/seungeunrho/minimalRL/blob/master/ppo.py\n",
    "* GNN 예제 : https://baeseongsu.github.io/posts/pytorch-geometric-introduction/\n",
    "* GNN 배치 단위 inference 하는법 : https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html\n",
    "* 지금 이 코드는 돌아가긴 하지만, 학습이 제대로 안되는 상황입니다. 모든 state에 대해서 한 액션으로 거의 모든 확률이 쏠려버리게끔 학습이 되는데, 원인은 찾지 못했습니다. 아마 제가 만든 환경에 문제가 있을 수도 있고, 학습 자체를 더 튜닝해야 될 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b4acf7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from library import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch_geometric.nn import NNConv, global_mean_pool, GraphUNet\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a5ce44",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate   = 0.001\n",
    "gamma           = 0.9\n",
    "entropy_weight  = 0.1\n",
    "'''\n",
    "entropy_weight : loss함수에 entropy라는 걸 더해주는 테크닉에서의 weight입니다.\n",
    "이 기법은 A3C 논문에 나와있으며, 쓰는 이유는 exploration을 촉진하기 위해서입니다.\n",
    "각 액션을 취할 확률을 거의 균등하게끔 업데이트해줌으로써 다양한 액션을 해볼 기회가 많아집니다.\n",
    "actor-critic에서 이 기법으로 인한 성능 개선이 매우 효과적인 것으로 알고있으므로, 적용해주시면 좋을 듯 합니다.\n",
    "'''\n",
    "lmbda         = 0.95\n",
    "eps_clip      = 0.1\n",
    "'''\n",
    "위 두 인자는 PPO에서 씁니다.\n",
    "'''\n",
    "\n",
    "loss_coef = 0.5\n",
    "\n",
    "node_feature_num = 100\n",
    "queue_feature_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c1fbf4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class actor_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(actor_network, self).__init__()\n",
    "        self.data = []\n",
    "\n",
    "        self.pi_mlp1 = nn.Sequential(nn.Linear(1, node_feature_num * node_feature_num), nn.ReLU())\n",
    "        self.pi_s_gcn = NNConv(node_feature_num, node_feature_num, self.pi_mlp1, aggr='mean')\n",
    "\n",
    "        self.pi_graph_u_net = GraphUNet(node_feature_num, 10, node_feature_num, 4, 0.8)\n",
    "\n",
    "        self.pi_backbone = nn.Sequential(\n",
    "            nn.Linear(200, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # prob_fc : 각 액션에 대한 확률.\n",
    "        self.pi_prob_fc = nn.Linear(64, 5)\n",
    "\n",
    "        self.v_mlp1 = nn.Sequential(nn.Linear(1, node_feature_num * node_feature_num), nn.ReLU())\n",
    "        self.v_s_gcn = NNConv(node_feature_num, node_feature_num, self.v_mlp1, aggr='mean')\n",
    "\n",
    "        self.v_graph_u_net = GraphUNet(node_feature_num, 10, node_feature_num, 4, 0.8)\n",
    "\n",
    "        self.v_backbone = nn.Sequential(\n",
    "            nn.Linear(200, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # prob_fc : 각 액션에 대한 확률.\n",
    "        self.v_value_fc = nn.Linear(64, 1)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "              \n",
    "        \n",
    "    # policy DNN\n",
    "    def pi(self, state):\n",
    "        data, job_waiting_feature = state # data = graph data\n",
    "        node_feature, link_feature, adjacency = data.x, data.edge_attr, data.edge_index\n",
    "        \"\"\"\n",
    "        node_feature = F.relu(self.conv1(node_feature, adjacency, link_feature))\n",
    "        node_feature = F.relu(self.conv2(node_feature, adjacency, link_feature))\n",
    "        #node_feature = F.relu(self.conv3(node_feature, adjacency, link_feature))\n",
    "        readout = global_mean_pool(node_feature, data.batch) # 모든 노드의 feature를 평균내서 하나의 벡터로 만들어주기.\n",
    "        \"\"\"\n",
    "\n",
    "        node_feature = F.relu(self.pi_s_gcn(node_feature, adjacency, link_feature))\n",
    "        node_feature = self.pi_graph_u_net(node_feature, adjacency)\n",
    "        readout = global_mean_pool(node_feature, data.batch)\n",
    "        print(\"readout\", readout.shape)\n",
    "        print(\"job_waiting_feature\", job_waiting_feature.shape)\n",
    "        concat = torch.cat([readout, job_waiting_feature], dim=1) # 여기에 job waiting 벡터 붙이기.\n",
    "\n",
    "        feature_extract = self.pi_backbone(concat)\n",
    "\n",
    "        output = self.pi_prob_fc(feature_extract)\n",
    "\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # 아래는 엔트로피 구하는 과정\n",
    "        log_prob = F.log_softmax(output, dim=1)\n",
    "        entropy = (log_prob * prob).sum(1, keepdim=True)\n",
    "        return prob, entropy      \n",
    "\n",
    "    # advantage network\n",
    "    def v(self, state):\n",
    "        data, job_waiting_feature = state\n",
    "        node_feature, link_feature, adjacency = data.x, data.edge_attr, data.edge_index\n",
    "        \"\"\"node_feature = F.relu(self.conv1(node_feature, adjacency, link_feature))\n",
    "        node_feature = F.relu(self.conv2(node_feature, adjacency, link_feature))\n",
    "        #node_feature = F.relu(self.conv3(node_feature, adjacency, link_feature))\n",
    "        readout = global_mean_pool(node_feature, data.batch)\n",
    "        \n",
    "        # job waiting vector concat\n",
    "        concat = torch.cat([readout, job_waiting_feature], dim=1)\"\"\"\n",
    "\n",
    "        node_feature = F.relu(self.v_s_gcn(node_feature, adjacency, link_feature))\n",
    "        node_feature = self.v_graph_u_net(node_feature, adjacency)\n",
    "        readout = global_mean_pool(node_feature, data.batch)\n",
    "        concat = torch.cat([readout, job_waiting_feature], dim=1) # 여기에 job waiting 벡터 붙이기.\n",
    "\n",
    "        feature_extract = self.v_backbone(concat)\n",
    "        \n",
    "        value = self.v_value_fc(feature_extract) # 앞부분은 pi랑 공유해야 하고, concat -> value_fc를 거치는 것만 다름.\n",
    "        return value\n",
    "        \n",
    "    def put_data(self, transition):\n",
    "        self.data.append(transition)\n",
    "        \n",
    "    \n",
    "    # make_batch, train_net은 맨 위에 코드 기반 링크와 거의 동일합니다.\n",
    "        \n",
    "    def make_batch(self):\n",
    "        network_lst, job_waiting_lst, a_lst, r_lst, next_network_lst, next_job_waiting_lst, prob_a_lst = [], [], [], [], [], [], []\n",
    "        entropy_lst = []\n",
    "        for transition in self.data:\n",
    "            network, job_waiting, a, r, nxt_network, nxt_job_waiting, prob_a, entropy = transition\n",
    "            network_lst.append(network)\n",
    "            job_waiting_lst.append(job_waiting)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            next_network_lst.append(nxt_network)\n",
    "            next_job_waiting_lst.append(nxt_job_waiting)\n",
    "            prob_a_lst.append([prob_a])\n",
    "            entropy_lst.append([entropy])\n",
    "        \n",
    "        # gnn sample을 배치단위로 inference하려면 이렇게 묶어줘야 함.\n",
    "        network_loader = DataLoader(network_lst, batch_size=len(network_lst))\n",
    "        next_network_loader = DataLoader(next_network_lst, batch_size=len(next_network_lst))\n",
    "        network_batch = next(iter(network_loader))\n",
    "        next_network_batch = next(iter(next_network_loader))\n",
    "        \n",
    "        job_waiting = torch.tensor(np.array(job_waiting_lst), dtype=torch.float)\n",
    "        a = torch.tensor(a_lst)\n",
    "        r = torch.tensor(r_lst, dtype=torch.float)\n",
    "        next_job_waiting = torch.tensor(np.array(next_job_waiting_lst), dtype=torch.float)\n",
    "        prob_a = torch.tensor(prob_a_lst, dtype=torch.float)\n",
    "        entropy = torch.tensor(entropy_lst, dtype=torch.float)\n",
    "        \n",
    "        self.data = []\n",
    "        return network_batch, job_waiting, a, r, next_network_batch, next_job_waiting, prob_a, entropy\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_net(self):\n",
    "        network_batch, job_waiting, a, r, next_network_batch, next_job_waiting, prob_a, entropy = self.make_batch()\n",
    "        \n",
    "        for i in range(5):\n",
    "            td_target = r + gamma * self.v([next_network_batch, next_job_waiting])\n",
    "            delta = td_target - self.v([network_batch, job_waiting])\n",
    "            delta = delta.detach().numpy()\n",
    "\n",
    "            advantage_lst = []\n",
    "            advantage = 0.0\n",
    "            for delta_t in delta[::-1]:\n",
    "                advantage = gamma * lmbda * advantage + delta_t[0]\n",
    "                advantage_lst.append([advantage])\n",
    "            advantage_lst.reverse()\n",
    "            advantage = torch.tensor(advantage_lst, dtype=torch.float)\n",
    "\n",
    "            v_loss = F.smooth_l1_loss(self.v([network_batch, job_waiting]) , td_target.detach())\n",
    "            print(\"v_loss\", v_loss)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            v_loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pi, _ = self.pi([network_batch, job_waiting])\n",
    "            pi_a = pi.gather(1,a)\n",
    "            ratio = torch.exp(torch.log(pi_a) - torch.log(prob_a))  # a/b == exp(log(a)-log(b))\n",
    "\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantage\n",
    "            #loss = -torch.min(surr1, surr2) + F.smooth_l1_loss(self.v([network_batch, job_waiting]) , td_target.detach())\n",
    "\n",
    "            pi_loss = -(torch.log(pi_a)) * advantage\n",
    "\n",
    "            print(\"pi_loss\", pi_loss)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            pi_loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768ca02f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n",
      "readout torch.Size([1, 100])\n",
      "job_waiting_feature torch.Size([1, 100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_loss tensor(7.4151, grad_fn=<SmoothL1LossBackward0>)\n",
      "readout torch.Size([299, 100])\n",
      "job_waiting_feature torch.Size([299, 100])\n",
      "pi_loss tensor([[86.5548],\n",
      "        [83.4770],\n",
      "        [83.4703],\n",
      "        [86.6301],\n",
      "        [90.1822],\n",
      "        [83.7659],\n",
      "        [88.6760],\n",
      "        [88.6436],\n",
      "        [90.1422],\n",
      "        [82.7589],\n",
      "        [90.7647],\n",
      "        [82.6566],\n",
      "        [82.6495],\n",
      "        [86.9683],\n",
      "        [88.6503],\n",
      "        [83.9831],\n",
      "        [87.0663],\n",
      "        [88.3705],\n",
      "        [89.5170],\n",
      "        [88.2782],\n",
      "        [87.5332],\n",
      "        [88.2821],\n",
      "        [83.2842],\n",
      "        [86.8353],\n",
      "        [83.9474],\n",
      "        [91.8027],\n",
      "        [89.3669],\n",
      "        [85.3640],\n",
      "        [90.0640],\n",
      "        [88.6239],\n",
      "        [90.0253],\n",
      "        [90.8701],\n",
      "        [86.3161],\n",
      "        [86.2483],\n",
      "        [90.9985],\n",
      "        [84.5889],\n",
      "        [84.5757],\n",
      "        [84.6111],\n",
      "        [87.9138],\n",
      "        [88.3174],\n",
      "        [90.0189],\n",
      "        [90.0460],\n",
      "        [90.0572],\n",
      "        [83.7043],\n",
      "        [85.2321],\n",
      "        [83.5489],\n",
      "        [88.1831],\n",
      "        [88.1644],\n",
      "        [91.0806],\n",
      "        [86.0181],\n",
      "        [84.2743],\n",
      "        [90.0901],\n",
      "        [90.1183],\n",
      "        [87.8595],\n",
      "        [91.0377],\n",
      "        [88.5581],\n",
      "        [88.5580],\n",
      "        [87.1663],\n",
      "        [89.4501],\n",
      "        [87.2064],\n",
      "        [81.8773],\n",
      "        [81.8677],\n",
      "        [88.1391],\n",
      "        [89.1582],\n",
      "        [88.1687],\n",
      "        [82.1454],\n",
      "        [88.0690],\n",
      "        [89.6675],\n",
      "        [89.8005],\n",
      "        [84.3597],\n",
      "        [88.1014],\n",
      "        [87.4566],\n",
      "        [90.4827],\n",
      "        [87.4427],\n",
      "        [87.4835],\n",
      "        [87.5426],\n",
      "        [90.3048],\n",
      "        [90.0895],\n",
      "        [90.1309],\n",
      "        [90.0848],\n",
      "        [87.9711],\n",
      "        [89.3506],\n",
      "        [89.3354],\n",
      "        [88.1244],\n",
      "        [84.3310],\n",
      "        [90.0025],\n",
      "        [84.5544],\n",
      "        [89.9305],\n",
      "        [84.5968],\n",
      "        [84.5381],\n",
      "        [87.3514],\n",
      "        [89.3991],\n",
      "        [84.4569],\n",
      "        [88.6933],\n",
      "        [87.4773],\n",
      "        [84.9234],\n",
      "        [87.0142],\n",
      "        [88.4479],\n",
      "        [86.9729],\n",
      "        [88.4828],\n",
      "        [85.2418],\n",
      "        [85.2380],\n",
      "        [88.7912],\n",
      "        [86.6212],\n",
      "        [86.0051],\n",
      "        [91.2582],\n",
      "        [85.7855],\n",
      "        [86.0047],\n",
      "        [87.3728],\n",
      "        [87.3584],\n",
      "        [84.1990],\n",
      "        [88.5473],\n",
      "        [91.3242],\n",
      "        [91.2973],\n",
      "        [85.8903],\n",
      "        [87.6554],\n",
      "        [85.7849],\n",
      "        [90.2011],\n",
      "        [85.7770],\n",
      "        [86.1565],\n",
      "        [85.0291],\n",
      "        [86.0987],\n",
      "        [85.0164],\n",
      "        [88.3280],\n",
      "        [84.7165],\n",
      "        [90.7894],\n",
      "        [84.6865],\n",
      "        [87.5415],\n",
      "        [90.2889],\n",
      "        [91.8226],\n",
      "        [91.8455],\n",
      "        [92.4113],\n",
      "        [85.8885],\n",
      "        [86.7114],\n",
      "        [90.9528],\n",
      "        [85.8014],\n",
      "        [88.9205],\n",
      "        [91.9807],\n",
      "        [87.7160],\n",
      "        [89.5563],\n",
      "        [87.8742],\n",
      "        [86.9131],\n",
      "        [91.9665],\n",
      "        [83.0704],\n",
      "        [89.1573],\n",
      "        [89.4022],\n",
      "        [84.1218],\n",
      "        [89.4480],\n",
      "        [84.0689],\n",
      "        [88.5184],\n",
      "        [82.9803],\n",
      "        [89.1867],\n",
      "        [82.9146],\n",
      "        [89.1060],\n",
      "        [90.7877],\n",
      "        [90.7684],\n",
      "        [90.7742],\n",
      "        [91.3557],\n",
      "        [82.9612],\n",
      "        [84.4244],\n",
      "        [84.3595],\n",
      "        [84.3467],\n",
      "        [87.6026],\n",
      "        [91.5820],\n",
      "        [86.4050],\n",
      "        [87.5102],\n",
      "        [89.1596],\n",
      "        [89.7153],\n",
      "        [89.3342],\n",
      "        [83.5177],\n",
      "        [83.1374],\n",
      "        [90.6734],\n",
      "        [87.5250],\n",
      "        [90.6561],\n",
      "        [89.1825],\n",
      "        [89.1390],\n",
      "        [82.7825],\n",
      "        [89.0795],\n",
      "        [88.0960],\n",
      "        [88.1732],\n",
      "        [88.6670],\n",
      "        [83.8773],\n",
      "        [82.6452],\n",
      "        [88.1103],\n",
      "        [89.6842],\n",
      "        [88.8877],\n",
      "        [90.2846],\n",
      "        [87.0176],\n",
      "        [91.4073],\n",
      "        [88.6715],\n",
      "        [91.3845],\n",
      "        [89.5007],\n",
      "        [90.2289],\n",
      "        [87.1780],\n",
      "        [87.2734],\n",
      "        [88.8423],\n",
      "        [88.8697],\n",
      "        [83.1754],\n",
      "        [90.6047],\n",
      "        [83.3840],\n",
      "        [83.3636],\n",
      "        [83.4032],\n",
      "        [87.9802],\n",
      "        [91.4412],\n",
      "        [88.8735],\n",
      "        [83.1066],\n",
      "        [89.2296],\n",
      "        [88.7764],\n",
      "        [86.9429],\n",
      "        [89.1915],\n",
      "        [82.6964],\n",
      "        [82.6787],\n",
      "        [88.5368],\n",
      "        [90.3281],\n",
      "        [88.2903],\n",
      "        [86.6860],\n",
      "        [90.2729],\n",
      "        [83.0359],\n",
      "        [88.3792],\n",
      "        [87.2018],\n",
      "        [82.7636],\n",
      "        [82.6945],\n",
      "        [90.4861],\n",
      "        [82.7427],\n",
      "        [90.7874],\n",
      "        [88.8212],\n",
      "        [82.8643],\n",
      "        [87.4653],\n",
      "        [90.8737],\n",
      "        [88.9874],\n",
      "        [89.6803],\n",
      "        [88.4699],\n",
      "        [88.4887],\n",
      "        [87.7250],\n",
      "        [89.3220],\n",
      "        [84.0113],\n",
      "        [89.3357],\n",
      "        [89.3050],\n",
      "        [87.6407],\n",
      "        [87.7586],\n",
      "        [85.3531],\n",
      "        [87.7283],\n",
      "        [89.8444],\n",
      "        [86.8817],\n",
      "        [87.8869],\n",
      "        [89.9125],\n",
      "        [87.9266],\n",
      "        [84.7572],\n",
      "        [89.5187],\n",
      "        [90.9306],\n",
      "        [86.6413],\n",
      "        [90.9281],\n",
      "        [89.2779],\n",
      "        [86.8937],\n",
      "        [85.1524],\n",
      "        [90.3600],\n",
      "        [85.7110],\n",
      "        [86.7715],\n",
      "        [86.5520],\n",
      "        [85.4654],\n",
      "        [88.0169],\n",
      "        [90.0823],\n",
      "        [85.1464],\n",
      "        [85.1413],\n",
      "        [89.9135],\n",
      "        [86.4003],\n",
      "        [88.7343],\n",
      "        [89.0138],\n",
      "        [88.9417],\n",
      "        [86.5713],\n",
      "        [86.5912],\n",
      "        [88.3546],\n",
      "        [83.8164],\n",
      "        [87.9739],\n",
      "        [85.7487],\n",
      "        [87.3284],\n",
      "        [87.4646],\n",
      "        [86.3528],\n",
      "        [82.4501],\n",
      "        [81.9033],\n",
      "        [83.4501],\n",
      "        [81.5663],\n",
      "        [79.9541],\n",
      "        [79.7760],\n",
      "        [78.5655],\n",
      "        [81.0496],\n",
      "        [74.3256],\n",
      "        [74.6765],\n",
      "        [68.9867],\n",
      "        [66.4564],\n",
      "        [67.2410],\n",
      "        [64.7683],\n",
      "        [58.9192],\n",
      "        [52.2860],\n",
      "        [48.0656],\n",
      "        [41.9480],\n",
      "        [32.5285],\n",
      "        [23.3593],\n",
      "        [12.5910]], grad_fn=<MulBackward0>)\n",
      "v_loss tensor(7.4085, grad_fn=<SmoothL1LossBackward0>)\n",
      "readout torch.Size([299, 100])\n",
      "job_waiting_feature torch.Size([299, 100])\n",
      "pi_loss tensor([[86.2700],\n",
      "        [82.2679],\n",
      "        [82.2581],\n",
      "        [86.3700],\n",
      "        [90.4196],\n",
      "        [83.1691],\n",
      "        [88.0440],\n",
      "        [88.0278],\n",
      "        [90.4056],\n",
      "        [81.3097],\n",
      "        [91.7778],\n",
      "        [81.2765],\n",
      "        [81.2764],\n",
      "        [85.8756],\n",
      "        [88.8030],\n",
      "        [82.5453],\n",
      "        [85.9274],\n",
      "        [86.5470],\n",
      "        [89.8530],\n",
      "        [86.4125],\n",
      "        [86.0553],\n",
      "        [88.1662],\n",
      "        [82.0380],\n",
      "        [85.4257],\n",
      "        [82.7746],\n",
      "        [92.6669],\n",
      "        [89.7454],\n",
      "        [86.4170],\n",
      "        [89.9877],\n",
      "        [86.9063],\n",
      "        [89.9478],\n",
      "        [92.0591],\n",
      "        [86.1374],\n",
      "        [86.1122],\n",
      "        [92.3134],\n",
      "        [82.4453],\n",
      "        [82.4396],\n",
      "        [82.4828],\n",
      "        [86.7457],\n",
      "        [87.0976],\n",
      "        [88.9650],\n",
      "        [88.9918],\n",
      "        [89.0064],\n",
      "        [82.2998],\n",
      "        [86.6772],\n",
      "        [82.5777],\n",
      "        [86.4893],\n",
      "        [86.4415],\n",
      "        [92.3140],\n",
      "        [87.4707],\n",
      "        [83.5728],\n",
      "        [88.6119],\n",
      "        [88.6152],\n",
      "        [86.5757],\n",
      "        [91.9863],\n",
      "        [87.7165],\n",
      "        [87.7344],\n",
      "        [85.9349],\n",
      "        [89.2748],\n",
      "        [85.9174],\n",
      "        [80.3239],\n",
      "        [80.3018],\n",
      "        [87.0719],\n",
      "        [89.9092],\n",
      "        [87.0757],\n",
      "        [81.1530],\n",
      "        [86.2876],\n",
      "        [91.1632],\n",
      "        [91.0379],\n",
      "        [82.5944],\n",
      "        [86.2832],\n",
      "        [85.7500],\n",
      "        [91.4963],\n",
      "        [85.6422],\n",
      "        [85.5983],\n",
      "        [85.6195],\n",
      "        [91.2331],\n",
      "        [89.9274],\n",
      "        [89.9768],\n",
      "        [89.9365],\n",
      "        [88.0057],\n",
      "        [90.2224],\n",
      "        [90.2168],\n",
      "        [88.1390],\n",
      "        [82.5348],\n",
      "        [90.5866],\n",
      "        [82.5754],\n",
      "        [90.5497],\n",
      "        [82.5756],\n",
      "        [82.5194],\n",
      "        [85.9203],\n",
      "        [89.4072],\n",
      "        [83.0023],\n",
      "        [89.6821],\n",
      "        [85.9329],\n",
      "        [83.4864],\n",
      "        [84.9362],\n",
      "        [88.4026],\n",
      "        [84.8936],\n",
      "        [88.4550],\n",
      "        [83.6340],\n",
      "        [83.6475],\n",
      "        [89.7116],\n",
      "        [84.9230],\n",
      "        [84.0946],\n",
      "        [92.9474],\n",
      "        [84.4434],\n",
      "        [84.0375],\n",
      "        [88.0422],\n",
      "        [88.1667],\n",
      "        [83.0358],\n",
      "        [86.4662],\n",
      "        [92.2724],\n",
      "        [92.2641],\n",
      "        [84.0099],\n",
      "        [86.0899],\n",
      "        [83.9345],\n",
      "        [91.3508],\n",
      "        [83.9456],\n",
      "        [86.9236],\n",
      "        [83.1222],\n",
      "        [86.8791],\n",
      "        [83.1523],\n",
      "        [87.0604],\n",
      "        [82.5241],\n",
      "        [91.7894],\n",
      "        [82.5224],\n",
      "        [85.9257],\n",
      "        [92.1322],\n",
      "        [90.6964],\n",
      "        [90.7016],\n",
      "        [91.6053],\n",
      "        [87.7105],\n",
      "        [84.5460],\n",
      "        [92.9571],\n",
      "        [87.6542],\n",
      "        [87.8111],\n",
      "        [93.7499],\n",
      "        [85.4713],\n",
      "        [88.3354],\n",
      "        [86.7735],\n",
      "        [88.1407],\n",
      "        [93.0745],\n",
      "        [82.1836],\n",
      "        [87.7440],\n",
      "        [88.5065],\n",
      "        [82.8150],\n",
      "        [88.5104],\n",
      "        [82.7773],\n",
      "        [89.6432],\n",
      "        [81.5631],\n",
      "        [89.5675],\n",
      "        [81.4896],\n",
      "        [89.5310],\n",
      "        [90.3835],\n",
      "        [90.3650],\n",
      "        [90.3853],\n",
      "        [92.1863],\n",
      "        [81.8787],\n",
      "        [82.5570],\n",
      "        [82.5136],\n",
      "        [82.4959],\n",
      "        [85.5362],\n",
      "        [91.4849],\n",
      "        [87.8981],\n",
      "        [85.4155],\n",
      "        [88.8564],\n",
      "        [90.5639],\n",
      "        [88.0705],\n",
      "        [82.7464],\n",
      "        [81.8421],\n",
      "        [91.4633],\n",
      "        [86.8973],\n",
      "        [91.8325],\n",
      "        [89.1299],\n",
      "        [89.1055],\n",
      "        [81.5610],\n",
      "        [89.6931],\n",
      "        [87.6057],\n",
      "        [87.6837],\n",
      "        [86.8680],\n",
      "        [83.4112],\n",
      "        [81.9364],\n",
      "        [86.3840],\n",
      "        [91.3350],\n",
      "        [89.0382],\n",
      "        [90.7582],\n",
      "        [85.6184],\n",
      "        [92.1423],\n",
      "        [89.8824],\n",
      "        [92.1473],\n",
      "        [89.6243],\n",
      "        [91.3245],\n",
      "        [85.4972],\n",
      "        [85.5408],\n",
      "        [89.0112],\n",
      "        [89.0196],\n",
      "        [81.9169],\n",
      "        [91.6763],\n",
      "        [81.8777],\n",
      "        [81.8713],\n",
      "        [81.8999],\n",
      "        [88.1834],\n",
      "        [92.6586],\n",
      "        [88.8335],\n",
      "        [82.0619],\n",
      "        [87.7654],\n",
      "        [89.3378],\n",
      "        [87.6537],\n",
      "        [87.6740],\n",
      "        [81.7629],\n",
      "        [81.7434],\n",
      "        [87.3003],\n",
      "        [91.6587],\n",
      "        [86.9871],\n",
      "        [87.5117],\n",
      "        [91.6940],\n",
      "        [81.2494],\n",
      "        [86.6504],\n",
      "        [88.7298],\n",
      "        [81.1020],\n",
      "        [81.0505],\n",
      "        [91.6374],\n",
      "        [81.0358],\n",
      "        [90.1439],\n",
      "        [86.9138],\n",
      "        [81.6018],\n",
      "        [88.7187],\n",
      "        [92.4651],\n",
      "        [87.0661],\n",
      "        [89.5494],\n",
      "        [86.5000],\n",
      "        [86.4857],\n",
      "        [88.7986],\n",
      "        [88.1039],\n",
      "        [83.0844],\n",
      "        [88.0927],\n",
      "        [88.0771],\n",
      "        [87.1362],\n",
      "        [86.7758],\n",
      "        [84.0344],\n",
      "        [86.7413],\n",
      "        [89.1259],\n",
      "        [87.9847],\n",
      "        [87.1891],\n",
      "        [89.1874],\n",
      "        [87.2227],\n",
      "        [83.5051],\n",
      "        [90.6294],\n",
      "        [90.2206],\n",
      "        [86.1256],\n",
      "        [90.2528],\n",
      "        [90.7368],\n",
      "        [88.0296],\n",
      "        [83.7041],\n",
      "        [89.6361],\n",
      "        [84.5171],\n",
      "        [87.9388],\n",
      "        [85.2517],\n",
      "        [84.5213],\n",
      "        [89.0802],\n",
      "        [91.3028],\n",
      "        [83.9524],\n",
      "        [83.9591],\n",
      "        [90.9937],\n",
      "        [84.9283],\n",
      "        [88.3217],\n",
      "        [88.6634],\n",
      "        [88.6047],\n",
      "        [85.6486],\n",
      "        [85.4155],\n",
      "        [89.2512],\n",
      "        [82.3716],\n",
      "        [88.8867],\n",
      "        [86.4457],\n",
      "        [87.9912],\n",
      "        [88.3564],\n",
      "        [87.1835],\n",
      "        [81.4957],\n",
      "        [80.9505],\n",
      "        [82.1526],\n",
      "        [82.1419],\n",
      "        [77.9488],\n",
      "        [78.0883],\n",
      "        [76.8760],\n",
      "        [82.3905],\n",
      "        [72.6978],\n",
      "        [73.0987],\n",
      "        [69.2054],\n",
      "        [66.6540],\n",
      "        [67.4571],\n",
      "        [65.5632],\n",
      "        [57.8182],\n",
      "        [53.1054],\n",
      "        [47.1735],\n",
      "        [41.7113],\n",
      "        [33.0574],\n",
      "        [22.9640],\n",
      "        [12.3775]], grad_fn=<MulBackward0>)\n",
      "v_loss tensor(7.4026, grad_fn=<SmoothL1LossBackward0>)\n",
      "readout torch.Size([299, 100])\n",
      "job_waiting_feature torch.Size([299, 100])\n",
      "pi_loss tensor([[86.0121],\n",
      "        [81.3053],\n",
      "        [81.2956],\n",
      "        [86.1900],\n",
      "        [90.4104],\n",
      "        [82.6341],\n",
      "        [87.5510],\n",
      "        [87.5677],\n",
      "        [90.4285],\n",
      "        [80.2688],\n",
      "        [92.5336],\n",
      "        [80.2105],\n",
      "        [80.2143],\n",
      "        [84.9057],\n",
      "        [89.1184],\n",
      "        [81.6778],\n",
      "        [84.9473],\n",
      "        [85.1899],\n",
      "        [90.0460],\n",
      "        [85.0536],\n",
      "        [84.7192],\n",
      "        [88.2909],\n",
      "        [81.2156],\n",
      "        [84.2681],\n",
      "        [82.0917],\n",
      "        [93.5610],\n",
      "        [90.0750],\n",
      "        [86.9487],\n",
      "        [89.8003],\n",
      "        [85.7373],\n",
      "        [89.7633],\n",
      "        [93.1979],\n",
      "        [85.7939],\n",
      "        [85.7680],\n",
      "        [93.6368],\n",
      "        [80.8065],\n",
      "        [80.8167],\n",
      "        [80.8599],\n",
      "        [85.4458],\n",
      "        [86.1735],\n",
      "        [88.1511],\n",
      "        [88.1919],\n",
      "        [88.1959],\n",
      "        [81.4917],\n",
      "        [87.6258],\n",
      "        [82.0423],\n",
      "        [85.2368],\n",
      "        [85.1607],\n",
      "        [93.3150],\n",
      "        [88.4444],\n",
      "        [83.4979],\n",
      "        [87.0731],\n",
      "        [87.1168],\n",
      "        [85.4953],\n",
      "        [92.8476],\n",
      "        [86.7265],\n",
      "        [86.7746],\n",
      "        [84.8354],\n",
      "        [88.9223],\n",
      "        [84.7535],\n",
      "        [79.2676],\n",
      "        [79.2661],\n",
      "        [86.0748],\n",
      "        [90.5700],\n",
      "        [86.0537],\n",
      "        [80.2404],\n",
      "        [84.9026],\n",
      "        [92.6247],\n",
      "        [91.7468],\n",
      "        [81.6148],\n",
      "        [84.7691],\n",
      "        [84.1890],\n",
      "        [92.5328],\n",
      "        [84.0607],\n",
      "        [84.0136],\n",
      "        [84.0153],\n",
      "        [91.9323],\n",
      "        [89.5820],\n",
      "        [89.6197],\n",
      "        [89.5848],\n",
      "        [87.9355],\n",
      "        [90.9348],\n",
      "        [90.9361],\n",
      "        [88.0737],\n",
      "        [81.1687],\n",
      "        [90.7128],\n",
      "        [81.2963],\n",
      "        [90.7219],\n",
      "        [81.2953],\n",
      "        [81.2681],\n",
      "        [84.6366],\n",
      "        [89.3625],\n",
      "        [81.9341],\n",
      "        [90.2970],\n",
      "        [84.6072],\n",
      "        [82.6883],\n",
      "        [83.2310],\n",
      "        [88.4637],\n",
      "        [83.1596],\n",
      "        [88.5678],\n",
      "        [82.8645],\n",
      "        [82.8603],\n",
      "        [89.8329],\n",
      "        [83.6541],\n",
      "        [82.5930],\n",
      "        [94.3123],\n",
      "        [83.6669],\n",
      "        [82.5207],\n",
      "        [88.1165],\n",
      "        [88.4517],\n",
      "        [82.4377],\n",
      "        [84.8893],\n",
      "        [92.9068],\n",
      "        [92.8988],\n",
      "        [83.1297],\n",
      "        [85.1245],\n",
      "        [83.1078],\n",
      "        [92.1911],\n",
      "        [83.1372],\n",
      "        [87.1273],\n",
      "        [81.9699],\n",
      "        [87.0884],\n",
      "        [81.9829],\n",
      "        [86.0979],\n",
      "        [80.9961],\n",
      "        [92.6517],\n",
      "        [80.9855],\n",
      "        [84.5469],\n",
      "        [93.7969],\n",
      "        [89.8172],\n",
      "        [89.8449],\n",
      "        [90.8172],\n",
      "        [88.7361],\n",
      "        [82.8917],\n",
      "        [94.5874],\n",
      "        [88.6728],\n",
      "        [86.6465],\n",
      "        [95.3322],\n",
      "        [83.7793],\n",
      "        [87.1523],\n",
      "        [86.0496],\n",
      "        [89.1917],\n",
      "        [94.0658],\n",
      "        [81.4982],\n",
      "        [86.3403],\n",
      "        [87.5128],\n",
      "        [81.7581],\n",
      "        [87.5005],\n",
      "        [81.7233],\n",
      "        [90.5146],\n",
      "        [80.3561],\n",
      "        [89.9013],\n",
      "        [80.2969],\n",
      "        [89.9066],\n",
      "        [89.9749],\n",
      "        [89.9619],\n",
      "        [89.9888],\n",
      "        [92.9609],\n",
      "        [81.0033],\n",
      "        [81.5105],\n",
      "        [81.4943],\n",
      "        [81.4929],\n",
      "        [84.0508],\n",
      "        [91.0252],\n",
      "        [89.0891],\n",
      "        [83.8889],\n",
      "        [88.2097],\n",
      "        [91.3136],\n",
      "        [87.3436],\n",
      "        [82.3138],\n",
      "        [80.9633],\n",
      "        [92.0217],\n",
      "        [86.4546],\n",
      "        [92.8905],\n",
      "        [88.9164],\n",
      "        [88.8980],\n",
      "        [80.6307],\n",
      "        [89.8624],\n",
      "        [87.4981],\n",
      "        [87.5936],\n",
      "        [85.7973],\n",
      "        [82.7531],\n",
      "        [81.4330],\n",
      "        [85.2958],\n",
      "        [92.4765],\n",
      "        [89.3420],\n",
      "        [90.8436],\n",
      "        [84.4762],\n",
      "        [92.9729],\n",
      "        [90.8487],\n",
      "        [93.0084],\n",
      "        [89.4817],\n",
      "        [92.4105],\n",
      "        [84.1162],\n",
      "        [84.1148],\n",
      "        [88.6607],\n",
      "        [88.6782],\n",
      "        [80.9353],\n",
      "        [92.6218],\n",
      "        [80.8663],\n",
      "        [80.8731],\n",
      "        [80.8885],\n",
      "        [88.0587],\n",
      "        [93.7293],\n",
      "        [88.7212],\n",
      "        [81.7229],\n",
      "        [86.6640],\n",
      "        [89.5520],\n",
      "        [87.7594],\n",
      "        [86.5230],\n",
      "        [81.1027],\n",
      "        [81.0747],\n",
      "        [86.3787],\n",
      "        [92.8420],\n",
      "        [86.0817],\n",
      "        [87.8734],\n",
      "        [93.2791],\n",
      "        [80.1387],\n",
      "        [85.1490],\n",
      "        [89.5624],\n",
      "        [80.1456],\n",
      "        [80.1074],\n",
      "        [92.5593],\n",
      "        [80.1129],\n",
      "        [89.6881],\n",
      "        [85.6343],\n",
      "        [80.6298],\n",
      "        [89.5529],\n",
      "        [93.9955],\n",
      "        [85.5589],\n",
      "        [89.1106],\n",
      "        [85.0914],\n",
      "        [85.0456],\n",
      "        [89.6951],\n",
      "        [87.1552],\n",
      "        [82.2934],\n",
      "        [87.1469],\n",
      "        [87.1523],\n",
      "        [86.7471],\n",
      "        [85.8056],\n",
      "        [82.9628],\n",
      "        [85.7737],\n",
      "        [88.3343],\n",
      "        [88.8309],\n",
      "        [86.7096],\n",
      "        [88.4266],\n",
      "        [86.7230],\n",
      "        [82.4335],\n",
      "        [91.7692],\n",
      "        [89.5404],\n",
      "        [85.6295],\n",
      "        [89.6148],\n",
      "        [91.9038],\n",
      "        [88.7581],\n",
      "        [82.7822],\n",
      "        [88.8876],\n",
      "        [83.5302],\n",
      "        [88.6450],\n",
      "        [84.4797],\n",
      "        [84.0030],\n",
      "        [89.7581],\n",
      "        [92.3323],\n",
      "        [82.8699],\n",
      "        [82.8584],\n",
      "        [91.8995],\n",
      "        [84.0109],\n",
      "        [88.1336],\n",
      "        [88.3257],\n",
      "        [88.2808],\n",
      "        [85.0047],\n",
      "        [84.5314],\n",
      "        [89.9418],\n",
      "        [81.5587],\n",
      "        [89.5779],\n",
      "        [86.6968],\n",
      "        [88.6496],\n",
      "        [89.1194],\n",
      "        [88.0448],\n",
      "        [80.6274],\n",
      "        [80.1075],\n",
      "        [81.0245],\n",
      "        [82.1718],\n",
      "        [76.9722],\n",
      "        [76.9635],\n",
      "        [75.7441],\n",
      "        [83.4150],\n",
      "        [71.8333],\n",
      "        [72.0902],\n",
      "        [68.7890],\n",
      "        [66.2310],\n",
      "        [67.6843],\n",
      "        [66.2371],\n",
      "        [57.0125],\n",
      "        [53.4007],\n",
      "        [46.5094],\n",
      "        [41.5572],\n",
      "        [33.2867],\n",
      "        [22.6471],\n",
      "        [12.2057]], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\학부연구\\rl code\\agent2.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 115>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000004?line=109'>110</a>\u001b[0m             env\u001b[39m.\u001b[39mmove_job()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000004?line=114'>115</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000004?line=115'>116</a>\u001b[0m     main()\n",
      "\u001b[1;32md:\\학부연구\\rl code\\agent2.ipynb Cell 5'\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000004?line=101'>102</a>\u001b[0m     sample[\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m per_timestep_reward\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000004?line=103'>104</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mdata) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m time \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000004?line=104'>105</a>\u001b[0m     model\u001b[39m.\u001b[39;49mtrain_net()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000004?line=106'>107</a>\u001b[0m \u001b[39m# 새로운 job을 발생시키는 코드.\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000004?line=107'>108</a>\u001b[0m \u001b[39mif\u001b[39;00m time\u001b[39m%\u001b[39m\u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32md:\\학부연구\\rl code\\agent2.ipynb Cell 4'\u001b[0m in \u001b[0;36mactor_network.train_net\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=130'>131</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=131'>132</a>\u001b[0m     td_target \u001b[39m=\u001b[39m r \u001b[39m+\u001b[39m gamma \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv([next_network_batch, next_job_waiting])\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=132'>133</a>\u001b[0m     delta \u001b[39m=\u001b[39m td_target \u001b[39m-\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv([network_batch, job_waiting])\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=133'>134</a>\u001b[0m     delta \u001b[39m=\u001b[39m delta\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=135'>136</a>\u001b[0m     advantage_lst \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32md:\\학부연구\\rl code\\agent2.ipynb Cell 4'\u001b[0m in \u001b[0;36mactor_network.v\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=70'>71</a>\u001b[0m node_feature, link_feature, adjacency \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_attr, data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=71'>72</a>\u001b[0m \u001b[39m\"\"\"node_feature = F.relu(self.conv1(node_feature, adjacency, link_feature))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=72'>73</a>\u001b[0m \u001b[39mnode_feature = F.relu(self.conv2(node_feature, adjacency, link_feature))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=73'>74</a>\u001b[0m \u001b[39m#node_feature = F.relu(self.conv3(node_feature, adjacency, link_feature))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=76'>77</a>\u001b[0m \u001b[39m# job waiting vector concat\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=77'>78</a>\u001b[0m \u001b[39mconcat = torch.cat([readout, job_waiting_feature], dim=1)\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=79'>80</a>\u001b[0m node_feature \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_s_gcn(node_feature, adjacency, link_feature))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=80'>81</a>\u001b[0m node_feature \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_graph_u_net(node_feature, adjacency)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%ED%95%99%EB%B6%80%EC%97%B0%EA%B5%AC/rl%20code/agent2.ipynb#ch0000003?line=81'>82</a>\u001b[0m readout \u001b[39m=\u001b[39m global_mean_pool(node_feature, data\u001b[39m.\u001b[39mbatch)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\torch_geometric\\nn\\conv\\nn_conv.py:101\u001b[0m, in \u001b[0;36mNNConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[0;32m     98\u001b[0m     x: OptPairTensor \u001b[39m=\u001b[39m (x, x)\n\u001b[0;32m    100\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, edge_attr\u001b[39m=\u001b[39;49medge_attr, size\u001b[39m=\u001b[39;49msize)\n\u001b[0;32m    103\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m x_r \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_weight:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:317\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[1;32m--> 317\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmsg_kwargs)\n\u001b[0;32m    318\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    319\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\torch_geometric\\nn\\conv\\nn_conv.py:113\u001b[0m, in \u001b[0;36mNNConv.message\u001b[1;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessage\u001b[39m(\u001b[39mself\u001b[39m, x_j: Tensor, edge_attr: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 113\u001b[0m     weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnn(edge_attr)\n\u001b[0;32m    114\u001b[0m     weight \u001b[39m=\u001b[39m weight\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_channels_l, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_channels)\n\u001b[0;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmatmul(x_j\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m), weight)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\torch\\nn\\modules\\activation.py:98\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\omnetTest\\lib\\site-packages\\torch\\nn\\functional.py:1442\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[0;32m   1441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1442\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   1443\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    env = system_manager()\n",
    "    model = actor_network()\n",
    "\n",
    "    reward_history = []\n",
    "    v_history = []\n",
    "    \n",
    "    # network topology의 edges(GNN 예제 링크 참고)\n",
    "    adjacency = torch.tensor([[0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4],\n",
    "                              [1, 2, 0, 2, 3, 0, 1, 3, 4, 1, 2, 4, 2, 3]], dtype=torch.long)\n",
    "\n",
    "    # for each time step\n",
    "    time = 0\n",
    "    while True:\n",
    "        #print('---------------------------------------------------------------------------')\n",
    "        node_state, link_state = env.get_state()  # 환경으로부터 실제 state를 관측해 옴(OMNeT++에서 얻어온 statistic로 대체되어야 함).\n",
    "        node_state = torch.tensor(node_state, dtype=torch.float)\n",
    "        link_state = torch.tensor(link_state, dtype=torch.float)\n",
    "        job_waiting_state = env.get_job_waiting_vector()\n",
    "        \n",
    "        env.init_job_progress()\n",
    "        \n",
    "        # actions through multiple inferences\n",
    "        scheduled_job_num = 0\n",
    "        # 시스템에 job이 꽉찼거나, 스케줄할 job이 없거나, 현재 timestep에서 스케줄링한 job 개수가 10개 이상이면 그만한다.\n",
    "        while env.activated_job_num < 10 and len(env.job_waiting_queue) > 0 and scheduled_job_num < 10:\n",
    "            # job waiting 제일 앞에 있는 job 가져와서 스케줄링 해야 함.\n",
    "            job_idx = env.assign_index()\n",
    "            job = env.job_waiting_queue[0]\n",
    "            subtasks = job.subtasks\n",
    "            offloading_vector = []\n",
    "            \n",
    "            # 이 job의 모든 subtasks(layers)를 스케줄링해야 함.\n",
    "            for order in range(len(subtasks)):\n",
    "                network_state = Data(x=node_state, edge_attr=link_state, edge_index=adjacency)\n",
    "                prob, entropy = model.pi([network_state, torch.tensor(np.array([job_waiting_state]), dtype=torch.float)])\n",
    "                #print(f'prob : {prob}')\n",
    "                \n",
    "                m = Categorical(prob)\n",
    "                node = m.sample().item()\n",
    "                #print(f'node : {node}')\n",
    "                offloading_vector.append(node)\n",
    "                \n",
    "                # state transition(환경으로부터 매번 state를 업데이트하는게 아닌, 현재 state를 기반으로 action에 해당하는 waiting만 더해줌).\n",
    "                # 아래의 구체적인 코드는 이해하시기 보단 OMNeT++에서 받아온 데이터로 새로 짜시는게 빠를 것 같습니다.\n",
    "                next_node_state = node_state.clone().detach()\n",
    "                next_job_waiting_state = job_waiting_state.copy()\n",
    "                \n",
    "                next_node_state[node][5*job.index+order] += (subtasks[order].comp_demand/100) # 100으로 나누는 이유 : 이렇게 해야 액션이 한쪽 노드로 쏠리게끔 학습이 되는 것을 어느정도 방지할 수 있는 것을 확인.\n",
    "                # 100으로 안나눠주면 너무 큰 값이 state에 추가되어서 inference시 가중치랑 곱해지면서 액션이 한쪽으로 확 쏠리는 걸로 예상됨.\n",
    "                next_network_state = Data(x=next_node_state, edge_attr=link_state, edge_index=adjacency)\n",
    "                next_job_waiting_state[5+order] = 0\n",
    "                \n",
    "                model.put_data([network_state, job_waiting_state, node, 0, next_network_state, next_job_waiting_state, prob[0][node].item(), entropy])\n",
    "                \n",
    "                node_state = next_node_state\n",
    "                job_waiting_state = next_job_waiting_state\n",
    "            \n",
    "            scheduled_job_num += 1\n",
    "            \n",
    "            # job을 시스템에 스케줄링.\n",
    "            env.schedule(job_idx, offloading_vector)\n",
    "            env.move_job() # backlog에 있는 job을 job waiting vector로 옮기는 것.\n",
    "            job_waiting_state = env.get_job_waiting_vector()\n",
    "        \n",
    "        \n",
    "        # 이 timestep이 끝날때까지 시간을 흘려줌(제가 만든 환경이므로 이런 코드가 필요합니다. OMNeT++은 그냥 시뮬레이션 하면서 시간이 자동으로 흐르므로 필요없습니다).\n",
    "        for ms in range(100):\n",
    "            env.step(time)\n",
    "            time += 1\n",
    "        \n",
    "        # 이 timestep이 끝나면, 했던 행동에 대한 reward 계산(이 tiemstep 동안 시스템에 있는 job의 진행정도)\n",
    "        # 지금 보상 계산하는 과정에서 살짝 오류가 있습니다. 보상을 계산하기 전에 이번 timestep에서 어떤 job이 끝나서 없어져 버리면 그 job에 대한 진행정도를 추적할 수 없어서 0이 됩니다.\n",
    "        # 여기서 보상을 계산하는 부분(즉, job의 진행정도 tracking)이 환경과 좀 관련 있기 때문에, 보상을 어떻게 계산할지를 새로 짜시는게 빠를 것 같습니다.\n",
    "        per_timestep_reward = env.get_reward()\n",
    "\n",
    "        #if per_timestep_reward == 0:\n",
    "        #    per_timestep_reward = 5\n",
    "        \n",
    "        #print(f'reward : {per_timestep_reward}')\n",
    "\n",
    "        if time > 100:\n",
    "\n",
    "            reward_history = reward_history[-500:]\n",
    "            reward_history.append(per_timestep_reward)\n",
    "\n",
    "\n",
    "            v_history = v_history[-500:]\n",
    "            v_history.append(int(model.v([network_state, torch.tensor(np.array([job_waiting_state]), dtype=torch.float)])[0]))\n",
    "\n",
    "        if time % 1000 == 0:\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.plot(reward_history)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.plot(v_history)\n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "        # 이 timestep에서 발생한 모든 샘플에 똑같은 보상 적용.\n",
    "        for sample in model.data:\n",
    "            sample[3] = per_timestep_reward\n",
    "\n",
    "        if len(model.data) > 0 and time % 1000 == 0:\n",
    "            model.train_net()\n",
    "        \n",
    "        # 새로운 job을 발생시키는 코드.\n",
    "        if time%10 == 0:\n",
    "            env.create_job(time)\n",
    "            env.move_job()\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnetTest",
   "language": "python",
   "name": "omnettest"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
